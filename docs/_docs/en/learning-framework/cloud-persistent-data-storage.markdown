---
title: Cloud Persistent Data Storage
permalink: en/learning-framework/cloud-persistent-data-storage
abstract: >- # this means to ignore newlines until "baseurl:"
  For database persistence the storage is simple and managed through a JDBC connection to a cloud or hosted DBMS server. File storage however is a bit more complicated. 
---
# Cloud Persistent Data Storage

The framework follows a microservice architecture using containers, which, by default uses **Ephemeral** storage.  That is, the storage lives and dies within the container -  if the container dies or the process running inside the container gets rebooted for some reason, the state of the container is lost. However, IDL and ETL services are generally composite services (APIs) that use finer grain services (APIs) to extract the source data, identify insert, update, and delete transactions between the old and new data, and processes the insert, update, and delete transactions, storing the intermediate data in files. Where this is simple in monolithic applications, where the files would simply live on the application server, this gets more difficult in a “stateless” microservice environment, where the application runs in a collection of pods within a larger collection of containers.

**Stateless** means that the application is meant to be run in isolation, does not maintain any state, and has no knowledge of any past transactions. Every time a stateless application starts operating it starts from scratch as if the operation is being carried out for the first time.  This characteristic makes it easy for an application instance to replace, delete, or distribute.

**Stateful** applications are those that manage a state in some way or another. These applications generate data that must be preserved and are dependent on some specific data such as certain calculations, user profiles or preferences, data in relational databases, etc. For these types of applications, you need a persistent storage backend that can cater to the storage needs of the application and data can persist beyond the life of the container or be used by other containers. This is the case for ETL services, where the old, new, and delta file are generated by separate fine-grained services and applied using a fourth fine grained service, that could run in different pods and/or different containers.  Therefore, these applications require **persistent** storage that remains available beyond the life of individual containers.


## Kubernetes volumes

Alone, Kubernetes let your application pod request for a volume with three different types of storage access modes: 

1. **Read Write Once (RWO)** - This mode allows a storage volume to be accessed by a single pod with read-write access. This is useful for applications requiring block storage with low latency, for example, database applications.
1. **Read Write Many (RWX)** - Applications that need to share the storage volume require RWX access mode. RWX lets developers attach a volume with multiple container pods in parallel to be able to share and access data on that volume. It also helps pods to autoscale in line with user demand while still sharing the same data source. Traditional file-based workloads and multi-instance applications are a good example of this.
1. **Read Write Once (ROX)** - This mode allows many nodes to access the storage volume in read-only mode. This is useful where you want to pre-populate a volume with static data and publish it to multiple application instances.

## Type of Storage
Applications also need to determine the type of storage required by containerized applications. Three available options are - **Block**, **File**, and **Object**.

All three storage types work in a similar manner for a containerized application as it works for any bare metal or virtual machine-based workload.

![Type of Storage]({{ site.baseurl }}/assets/images/docs/types-of-storage.png)

## Understanding Persistent storage Options for Containers
Persistent storage in the Kubernetes environment is important because as more and more applications are containerized, the need to consume and share the data increases exponentially. Without having any persistent storage in place data sharing becomes impossible.

Looking at the options for persistent storage with Kubernetes there are **Host-Based Persistence**, **Volume Plugins**, and the **Container Storage Interface (CSI)**.

### Host-Based Persistence

In **Host-Based Persistence**, a pod depends on the storage available on the local worker node the pod is running on.  Within this there are two options, a **HostPath** and **LocalVolume**.  HostPath volume mounts a file or directory from the host node's filesystem into the Pod. **Local volume** mounts the local host’s storage devices such as a disk or partition into a specific local location in the pod. For both options, when an application writes to the folder in the container, data gets written to the local disk/volume. Since the actual data location is outside the container this storage can be persisted even if the pod is terminated.  However, if the host is unhealthy or a container pod gets deleted and reprovisioned on another host it will lose access to the storage as it had on the earlier node. 

### Volume Plugins

Kubernetes primary solution to a true persistent storage is **Volume Plugins** which enables pods to access volumes from 3rd party external storage (i.e., SAN, NAS, Software defined storage, etc.). Volume plugins are In-Tree storage drivers, which means these storage drivers as part of Core Kubernetes codes and their lifecycle is managed along with the release cycle of Kubernetes code.

Volume plugins (drivers) manages the entire lifecycle of persistent volume right from the creation, mapping, deletion of a volume coming from external storage. Kubernetes supports these plugins from cloud storage as well as on-premise storage subsystems.

{: style="text-align: center;" }
![Volume Plugins]({{ site.baseurl }}/assets/images/docs/volume-plugins.png){: style="width:60%;"}

The `PersistentVolume` subsystem provides an API for users and administrators that abstracts details of how storage is provided from how it is consumed. To do this, K8 introduced two API resources: `PersistentVolume` and `PersistentVolumeClaim`.

A **PersistentVolume (PV)** is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using **Storage Classes**. It is a resource in the cluster just like a node is a cluster resource. PVs are volume plugins like Volumes, but have a lifecycle independent of any individual Pod that uses the PV. This API object captures the details of the implementation of the storage, be that NFS, iSCSI, or a cloud-provider-specific storage system.

A **PersistentVolumeClaim (PVC)** is a request for storage by a user. It is similar to a Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific size and access modes (e.g., ReadWriteOnce, ReadOnlyMany or ReadWriteMany).

### Container Storage Interface (CSI)  
**CSI** drivers are another type of storage plugins in Kubernetes but unlike volume plugins which are in-tree, CSI drivers are Out-of-tree meaning these drivers enable storage vendors to create custom storage plugins without adding their plugin source code to the Kubernetes repository.

## OpenShift Container Storage (OCS)

OpenShift Container Storage is one of the leading Software-defined storage solutions and fits into almost every use case of a container storage strategy.  OCS is a software-defined storage solution specifically built for container environments to deliver container-native storage services. As the name implies, it is highly integrated and Integrated with OpenShift Container Platform (OCP). It gives data a permanent place to live, even when containers spin up and down, and easily scales across bare metal, virtual, container, and cloud deployments. OCS's unique features and capabilities keep it apart from all other available storage solutions available for Openshift. 

### OCS Architecture

OCS platform is built upon the foundation of a combined stack of multiple open source community projects and is tightly integrated with Openshift.

{: style="text-align: center;" }
![OCS Architecture]({{ site.baseurl }}/assets/images/docs/ocs-architecture.png){: style="width:50%;"}

- **CEPH Storage** - Ceph is an industry-proven and one of the widely adopted software-defined storage solutions. Ceph abstracts local storage and transforms it into a massively scalable storage cluster that can easily scale to a petabyte with no single point of failure. Ceph is also a unified storage platform that provides object, block, and file storage out of the same platform. OCS uses CEPH for the underlying Storage platform.

- **ROOK Project** - Rook is a cloud-native storage orchestrator which takes care of automated deployment and lifecycle management of backend storage. Rook abstracts all complex ceph tasks and, in OCS, Rook has Ceph storage as its backend. 

- **NOOBA Project** - Nooba is an enabler of Object storage for the OCS platform as it augments OCS with a Multi-Cloud Object storage service. NooBaa runs on Openshift, provides an object interface with an S3 compatible API to clients both inside and outside the Openshift cluster, and uses backend storage resources from local clusters as well as from the public cloud provided storage. 

Based on 100% open source technology and built of community projects which means no vendor locking and no proprietary code. All OCS components run as containers on top of Openshift itself.

OCS since its version 4.2 has complied to Container Storage Interface (CSI). CSI was introduced as a standard interface to connect storage arrays to the container orchestrators such as Kubernetes for provisioning persistent volumes (PVs). 


# Creating OCFS in Cirrus

You can now create volumes directly in the Cirrus OpenShift clusters and mount them to your containers (see [Container volumes backed by OpenShift container file storage](https://pages.github.ibm.com/CIOCloud/cio-blog/openshift-filestorage-volumes/){: target="_blank" }).

- Within your **Project**, proceed to the **Volumes** tab and click **New Volume**.
- Follow the instructions within the form and enter all required fields.
- **Submit** the form and wait until your volume reaches the **Bound** status.
- Navigate to the Application you want to associate this volume with.
- Click the pencil next to **Attached volumes**
- Select the volume, specify the mount path (e.g., `/app/src/storage`), and submit.


# References
1. [An insight into Persistent storage for Kubernetes](https://www.linkedin.com/pulse/insight-persistent-storage-kubernetes-jitender-kohli/), published February 11, 2021, by **Jitender Kohli**, Enterprise Architect at Red Hat 
1. [Kubernetes Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)
1. [Product Documentation for Red Hat OpenShift Container Storage 4.8](https://access.redhat.com/documentation/en-us/red_hat_openshift_container_storage/4.8)
1. [An analysis of OpenShift Container Storage (OCS) - The Champion of Storage](https://www.linkedin.com/pulse/analysis-openshift-container-storage-ocs-champion-jitender-kohli/), published February 11, 2021, by **Jitender Kohli**, Enterprise Architect at Red Hat 


